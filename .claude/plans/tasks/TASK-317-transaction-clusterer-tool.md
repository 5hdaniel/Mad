# Task TASK-317: Transaction Clusterer Tool

## Goal

Create a pure-function AI tool that groups analyzed messages into transaction clusters based on property address, participants, and communication patterns, identifying distinct real estate transactions from a set of emails.

## Non-Goals

- Do NOT implement the hybrid extraction pipeline (TASK-320)
- Do NOT modify transactionService or transactionExtractorService
- Do NOT create prompt templates in this task (TASK-318)
- Do NOT implement prompt versioning (TASK-319)
- Do NOT add IPC handlers or UI components
- Do NOT save clusters to database (that's the caller's responsibility)

## Deliverables

1. New file: `electron/services/llm/tools/clusterTransactionsTool.ts`
2. Update file: `electron/services/llm/tools/types.ts` (add TransactionCluster types)

## Acceptance Criteria

- [ ] `clusterTransactions()` accepts analyzed messages and returns `TransactionCluster[]`
- [ ] Groups messages by property address (primary clustering key)
- [ ] Each cluster includes confidence score (0-1)
- [ ] Each cluster identifies transaction type (purchase/sale/lease)
- [ ] Each cluster includes date range (first/last communication)
- [ ] Each cluster includes suggested contacts from messages
- [ ] Generates human-readable summary for each cluster
- [ ] Handles overlapping/ambiguous clusters with lower confidence
- [ ] Works with both OpenAI and Anthropic providers via BaseLLMService
- [ ] Validates LLM response against JSON schema before returning
- [ ] Handles malformed LLM responses gracefully (returns error result)
- [ ] All CI checks pass

## Implementation Notes

### Key Patterns

```typescript
// Add to electron/services/llm/tools/types.ts
export interface TransactionCluster {
  clusterId: string; // UUID generated by tool
  propertyAddress: string;
  confidence: number; // 0-1
  transactionType: 'purchase' | 'sale' | 'lease' | null;
  stage: 'prospecting' | 'active' | 'pending' | 'closing' | 'closed' | null;
  communicationIds: string[]; // IDs of messages in this cluster
  dateRange: {
    start: string; // ISO date
    end: string; // ISO date
  };
  suggestedContacts: Array<{
    name: string;
    email?: string;
    role?: string;
  }>;
  summary: string; // Human-readable description
}

export interface ClusterTransactionsInput {
  analyzedMessages: Array<{
    id: string; // Message ID for tracking
    subject: string;
    sender: string;
    recipients: string[];
    date: string;
    analysis: MessageAnalysis; // From TASK-315
  }>;
  existingTransactions?: Array<{
    id: string;
    propertyAddress: string;
    transactionType?: string;
  }>;
}

export interface ClusterTransactionsOutput {
  clusters: TransactionCluster[];
  unclustered: string[]; // Message IDs that couldn't be clustered
}
```

```typescript
// electron/services/llm/tools/clusterTransactionsTool.ts
import { v4 as uuidv4 } from 'uuid';
import { BaseLLMService } from '../baseLLMService';
import { LLMConfig, LLMMessage } from '../types';
import {
  TransactionCluster,
  ClusterTransactionsInput,
  ClusterTransactionsOutput,
  ToolResult,
} from './types';
import { ContentSanitizer } from '../contentSanitizer';

export class ClusterTransactionsTool {
  private llmService: BaseLLMService;
  private sanitizer: ContentSanitizer;

  constructor(llmService: BaseLLMService) {
    this.llmService = llmService;
    this.sanitizer = new ContentSanitizer();
  }

  async cluster(
    input: ClusterTransactionsInput,
    config: LLMConfig
  ): Promise<ToolResult<ClusterTransactionsOutput>> {
    const startTime = Date.now();

    try {
      // Pre-cluster by address for efficiency (reduce LLM calls)
      const addressGroups = this.preClusterByAddress(input.analyzedMessages);

      // If only one group with clear address, skip LLM
      if (addressGroups.size === 1) {
        const [address, messages] = [...addressGroups.entries()][0];
        if (address !== 'unknown') {
          return {
            success: true,
            data: {
              clusters: [this.createClusterFromGroup(address, messages)],
              unclustered: [],
            },
            latencyMs: Date.now() - startTime,
          };
        }
      }

      // Use LLM for complex clustering
      const messages = this.buildPrompt(input);

      const response = await this.llmService.completeWithRetry(messages, {
        ...config,
        maxTokens: 2500, // May need more for multiple clusters
      });

      const output = this.parseResponse(response.content, input.analyzedMessages);

      return {
        success: true,
        data: output,
        tokensUsed: response.tokensUsed,
        latencyMs: Date.now() - startTime,
      };
    } catch (error) {
      return {
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error',
        latencyMs: Date.now() - startTime,
      };
    }
  }

  private preClusterByAddress(
    messages: ClusterTransactionsInput['analyzedMessages']
  ): Map<string, ClusterTransactionsInput['analyzedMessages']> {
    const groups = new Map<string, ClusterTransactionsInput['analyzedMessages']>();

    messages.forEach(msg => {
      // Get primary address from analysis
      const address = msg.analysis.extractedEntities.addresses[0]?.value || 'unknown';
      const normalized = this.normalizeAddress(address);

      if (!groups.has(normalized)) {
        groups.set(normalized, []);
      }
      groups.get(normalized)!.push(msg);
    });

    return groups;
  }

  private normalizeAddress(address: string): string {
    // Basic normalization: lowercase, remove extra spaces
    return address
      .toLowerCase()
      .replace(/\s+/g, ' ')
      .replace(/,\s*/g, ', ')
      .trim();
  }

  private createClusterFromGroup(
    address: string,
    messages: ClusterTransactionsInput['analyzedMessages']
  ): TransactionCluster {
    const dates = messages.map(m => new Date(m.date).getTime()).sort((a, b) => a - b);

    // Aggregate transaction type from analyses
    const types = messages
      .map(m => m.analysis.transactionIndicators.type)
      .filter(Boolean);
    const typeCount = types.reduce((acc, t) => {
      acc[t!] = (acc[t!] || 0) + 1;
      return acc;
    }, {} as Record<string, number>);
    const dominantType = Object.entries(typeCount)
      .sort((a, b) => b[1] - a[1])[0]?.[0] as 'purchase' | 'sale' | 'lease' | null || null;

    // Aggregate stage
    const stages = messages
      .map(m => m.analysis.transactionIndicators.stage)
      .filter(Boolean);
    const stageCount = stages.reduce((acc, s) => {
      acc[s!] = (acc[s!] || 0) + 1;
      return acc;
    }, {} as Record<string, number>);
    const dominantStage = Object.entries(stageCount)
      .sort((a, b) => b[1] - a[1])[0]?.[0] || null;

    // Aggregate contacts
    const contactMap = new Map<string, { name: string; email?: string; role?: string }>();
    messages.forEach(m => {
      m.analysis.extractedEntities.contacts.forEach(c => {
        const key = (c.email || c.name).toLowerCase();
        if (!contactMap.has(key)) {
          contactMap.set(key, {
            name: c.name,
            email: c.email,
            role: c.suggestedRole,
          });
        }
      });
    });

    // Calculate confidence from individual message confidences
    const avgConfidence = messages.reduce((sum, m) => sum + m.analysis.confidence, 0) / messages.length;

    return {
      clusterId: uuidv4(),
      propertyAddress: address,
      confidence: avgConfidence,
      transactionType: dominantType,
      stage: dominantStage as any,
      communicationIds: messages.map(m => m.id),
      dateRange: {
        start: new Date(dates[0]).toISOString(),
        end: new Date(dates[dates.length - 1]).toISOString(),
      },
      suggestedContacts: [...contactMap.values()],
      summary: this.generateSummary(address, messages.length, dominantType, dominantStage),
    };
  }

  private generateSummary(
    address: string,
    msgCount: number,
    type: string | null,
    stage: string | null
  ): string {
    const typeStr = type ? `${type} ` : '';
    const stageStr = stage ? ` (${stage})` : '';
    return `${typeStr}transaction at ${address}${stageStr} with ${msgCount} related communications`;
  }

  private buildPrompt(input: ClusterTransactionsInput): LLMMessage[] {
    const systemPrompt = `You are a real estate transaction analyst. Group the provided email analyses into distinct transaction clusters.

IMPORTANT: Return ONLY valid JSON matching this exact schema:
{
  "clusters": [
    {
      "propertyAddress": string,
      "messageIds": [string],
      "transactionType": "purchase" | "sale" | "lease" | null,
      "stage": "prospecting" | "active" | "pending" | "closing" | "closed" | null,
      "confidence": number (0-1),
      "summary": string (1-2 sentence description)
    }
  ],
  "unclustered": [string] (message IDs that don't clearly belong to any transaction)
}

Clustering rules:
1. Primary grouping key is property address
2. Messages about the same property belong together
3. If address is unclear, use participant overlap as secondary signal
4. Separate overlapping timeframes with different properties
5. Mark ambiguous assignments with lower confidence`;

    let userPrompt = `Group these analyzed emails into transaction clusters:\n\n`;

    if (input.existingTransactions && input.existingTransactions.length > 0) {
      userPrompt += `Existing transactions (for reference):\n`;
      input.existingTransactions.forEach(t => {
        userPrompt += `- ${t.propertyAddress} (${t.transactionType || 'unknown type'})\n`;
      });
      userPrompt += '\n';
    }

    userPrompt += `Analyzed messages:\n\n`;
    input.analyzedMessages.forEach((msg, i) => {
      userPrompt += `Message ${i + 1} (ID: ${msg.id}):\n`;
      userPrompt += `- Subject: ${this.sanitizer.sanitize(msg.subject)}\n`;
      userPrompt += `- From: ${msg.sender}\n`;
      userPrompt += `- Date: ${msg.date}\n`;
      userPrompt += `- Is RE: ${msg.analysis.isRealEstateRelated}, Confidence: ${msg.analysis.confidence}\n`;
      if (msg.analysis.extractedEntities.addresses.length > 0) {
        userPrompt += `- Addresses: ${msg.analysis.extractedEntities.addresses.map(a => a.value).join(', ')}\n`;
      }
      if (msg.analysis.transactionIndicators.type) {
        userPrompt += `- Type: ${msg.analysis.transactionIndicators.type}, Stage: ${msg.analysis.transactionIndicators.stage || 'unknown'}\n`;
      }
      userPrompt += '\n';
    });

    return [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userPrompt },
    ];
  }

  private parseResponse(
    content: string,
    originalMessages: ClusterTransactionsInput['analyzedMessages']
  ): ClusterTransactionsOutput {
    // Extract JSON from response
    let jsonStr = content;
    const jsonMatch = content.match(/```(?:json)?\s*([\s\S]*?)```/);
    if (jsonMatch) {
      jsonStr = jsonMatch[1].trim();
    }

    const parsed = JSON.parse(jsonStr);

    // Build message lookup for enrichment
    const msgLookup = new Map(originalMessages.map(m => [m.id, m]));

    const clusters: TransactionCluster[] = (parsed.clusters || []).map((c: any) => {
      const messageIds = c.messageIds || [];
      const messages = messageIds
        .map((id: string) => msgLookup.get(id))
        .filter(Boolean);

      // Calculate date range from messages
      const dates = messages.map((m: any) => new Date(m.date).getTime()).sort((a: number, b: number) => a - b);

      // Aggregate contacts from messages
      const contactMap = new Map<string, { name: string; email?: string; role?: string }>();
      messages.forEach((m: any) => {
        m.analysis.extractedEntities.contacts.forEach((contact: any) => {
          const key = (contact.email || contact.name).toLowerCase();
          if (!contactMap.has(key)) {
            contactMap.set(key, {
              name: contact.name,
              email: contact.email,
              role: contact.suggestedRole,
            });
          }
        });
      });

      return {
        clusterId: uuidv4(),
        propertyAddress: c.propertyAddress || 'Unknown',
        confidence: Math.max(0, Math.min(1, c.confidence || 0.5)),
        transactionType: c.transactionType || null,
        stage: c.stage || null,
        communicationIds: messageIds,
        dateRange: {
          start: dates.length > 0 ? new Date(dates[0]).toISOString() : new Date().toISOString(),
          end: dates.length > 0 ? new Date(dates[dates.length - 1]).toISOString() : new Date().toISOString(),
        },
        suggestedContacts: [...contactMap.values()],
        summary: c.summary || `Transaction at ${c.propertyAddress}`,
      };
    });

    return {
      clusters,
      unclustered: parsed.unclustered || [],
    };
  }
}
```

### Important Details

- Pre-cluster by address to reduce LLM calls when clustering is obvious
- Generate UUIDs for cluster IDs (not message IDs)
- Aggregate confidence from individual message analyses
- Include existing transactions as context for better clustering
- Handle unclustered messages explicitly

## Integration Notes

- Imports from: `electron/services/llm/baseLLMService.ts`, `electron/services/llm/contentSanitizer.ts`, `uuid`
- Imports types from: `electron/services/llm/tools/types.ts` (MessageAnalysis from TASK-315)
- Exports to: `electron/services/extraction/hybridExtractorService.ts` (TASK-320)
- Used by: TASK-320 (Hybrid Extractor Service)
- Depends on: SPRINT-004 LLM infrastructure, TASK-315 types
- Parallel with: TASK-315 (Message Analyzer), TASK-316 (Contact Role Extractor)

## Do / Don't

### Do:
- Use pre-clustering to minimize LLM calls
- Generate unique cluster IDs with UUID
- Calculate date ranges from actual message dates
- Include existing transactions as clustering hints
- Handle edge cases (no messages, all unclustered)

### Don't:
- Send full message bodies to LLM (use analysis summaries)
- Assume all messages will cluster
- Skip validation of LLM response
- Create clusters with empty propertyAddress
- Hardcode model names (use config)

## When to Stop and Ask

- If MessageAnalysis type from TASK-315 is not yet defined
- If uuid package is not installed
- If you need to modify existing LLM services
- If clustering logic becomes too complex for single LLM call

## Testing Expectations (MANDATORY)

### Unit Tests

- Required: Yes
- New tests to write:
  - `clusterTransactionsTool.test.ts`:
    - Test single-address clustering (no LLM needed)
    - Test multi-address clustering (LLM path)
    - Test with existing transactions context
    - Test unclustered messages handling
    - Test date range calculation
    - Test contact aggregation
    - Test confidence aggregation
    - Test JSON parsing with code block wrapper
    - Test malformed JSON handling

### Coverage

- Coverage impact:
  - Target 80%+ for this new file

### Integration / Feature Tests

- Required scenarios:
  - Messages about same address cluster together
  - Messages about different addresses create separate clusters
  - Low-confidence messages may be unclustered

### CI Requirements

This task's PR MUST pass:
- [ ] Unit tests
- [ ] Integration tests (if applicable)
- [ ] Coverage checks
- [ ] Type checking
- [ ] Lint / format checks

**PRs without tests when required WILL BE REJECTED.**

## PR Preparation

- **Title**: `feat(llm): add transaction clusterer tool [TASK-317]`
- **Labels**: `llm`, `ai-mvp`, `phase-1`
- **Depends on**: None (Phase 1 parallel task, but uses types from TASK-315)

---

## PM Estimate Breakdown (PM-Owned)

**Category:** `service`

**Estimated Totals:**
- **Turns:** 5-7
- **Tokens:** ~25K-35K
- **Time:** ~30-40m

**Estimation Assumptions:**

| Factor | Assumption | Est. Turns |
|--------|------------|------------|
| Files to create | 1 new file (tool) | +1 |
| Files to modify | 1 file (types.ts) | +1 |
| Code volume | ~250 lines (more complex logic) | +2.5 |
| Functions/handlers | 5 main functions (cluster, preCluster, buildPrompt, parseResponse, helpers) | +1.5 |
| Core files touched | No (electron main/preload unchanged) | +0 |
| New patterns | Following TASK-315 pattern with pre-clustering optimization | +0.5 |
| Test complexity | Medium (mocking LLM responses, date handling) | +1.5 |
| Dependencies | 1 service + uuid package | +0 |

**Confidence:** Medium

**Risk factors:**
- Pre-clustering logic complexity
- Date range edge cases
- Contact aggregation deduplication

**Similar past tasks:** TASK-315/316 (LLM tools, estimated 5-8 turns)

---

## Implementation Summary (Engineer-Owned)

**REQUIRED: You MUST complete this section before opening your PR.**
**PRs will be REJECTED if this section is incomplete.**

*Completed: 2025-12-18*

### Plan-First Protocol

```
Plan Agent Invocations:
- [x] Initial plan created (inline - followed TASK-315 pattern)
- [x] Plan reviewed from Engineer perspective
- [x] Plan approved (revisions: 0)

Plan Agent Metrics:
| Activity | Turns | Tokens (est.) | Time |
|----------|-------|---------------|------|
| Initial Plan | 1 | ~3K | 2 min |
| Revision(s) | 0 | 0 | 0 min |
| **Plan Total** | 1 | ~3K | 2 min |
```

### Checklist

```
Files created:
- [x] electron/services/llm/tools/clusterTransactionsTool.ts
- [x] electron/services/llm/tools/__tests__/clusterTransactionsTool.test.ts

Files modified:
- [x] electron/services/llm/tools/types.ts (TransactionCluster types added)

Features implemented:
- [x] TransactionCluster interface defined
- [x] clusterTransactions() function working
- [x] Pre-clustering optimization by address
- [x] Date range calculation from messages
- [x] Contact aggregation from message analyses
- [x] Summary generation

Verification:
- [x] npm run type-check passes
- [x] npm run lint passes (warnings only)
- [x] npm test passes (16 tests)
```

### Engineer Metrics

```
| Phase | Turns | Tokens | Time |
|-------|-------|--------|------|
| Planning (Plan) | 1 | ~3K | 2 min |
| Implementation (Impl) | 3 | ~12K | 10 min |
| Debugging (Debug) | 1 | ~2K | 2 min |
| **Engineer Total** | 5 | ~17K | 14 min |
```

### Notes

**Planning notes:**
Most complex of the three tools due to pre-clustering optimization. Followed TASK-315 pattern for LLM interaction.

**Deviations from plan:**
None - followed task spec closely.

**Design decisions:**
Pre-clustering skips LLM call when all messages have same address (saves API costs). Address normalization is basic (lowercase, trim) - can enhance later. UUID generated via uuid package.

**Issues encountered:**
Required @types/uuid installation for TypeScript support. Minor test fix for error message wrapping.

**Reviewer notes:**
Pre-clustering optimization is tested - verifies no LLM call when single address group. Date range handles empty arrays gracefully.

### Estimate vs Actual Analysis

**REQUIRED: Compare PM estimates to actuals to improve future predictions.**

| Factor | PM Assumed | Actual | Delta | Why Different? |
|--------|------------|--------|-------|----------------|
| Files to create | 1 | 2 | +1 | Added test file |
| Files to modify | 1 | 1 | 0 | As expected |
| Code volume | ~250 lines | ~310 lines | +60 | More helper methods |
| Functions/handlers | 5 | 8 | +3 | Validation + summary helpers |
| Core files touched | No | No | - | - |
| New patterns | Partial | Partial | - | Pre-clustering as documented |
| Test complexity | Medium | Medium | - | As expected |

**Total Variance:** Est 5-7 turns -> Actual 5 turns (17% under)

**Root cause of variance:**
Pattern from TASK-315 applied, pre-clustering logic was well-documented in task spec.

**Suggestion for similar tasks:**
Tools with optimization logic may need 10-20% more code but same turn count if well-documented.

---

## SR Engineer Review Notes

**Review Date:** 2025-12-18 | **Status:** APPROVED

### Branch Information (SR Engineer decides)
- **Branch From:** develop
- **Branch Into:** int/ai-tools
- **Suggested Branch Name:** feature/TASK-317-transaction-clusterer

### Execution Classification
- **Parallel Safe:** Yes (with TASK-315, TASK-316)
- **Depends On:** None (Phase 1 parallel), but uses types from TASK-315
- **Blocks:** TASK-318 (prompt extraction), TASK-320 (hybrid extractor)

### Shared File Analysis
- Files created:
  - `electron/services/llm/tools/clusterTransactionsTool.ts` (new)
- Files modified:
  - `electron/services/llm/tools/types.ts` (adds TransactionCluster types)
- Conflicts with: TASK-315, TASK-316 on `types.ts`
- **Resolution:** Same as TASK-316 - merge in sequence to int/ai-tools

### Technical Considerations
- Pre-clustering optimization reduces LLM calls (good for budget)
- Requires `uuid` package - verify it's already in dependencies
- Uses `MessageAnalysis` type from TASK-315 - type import only, runtime safe
- Complex logic in `preClusterByAddress` and `parseResponse` needs good test coverage
- Address normalization is basic - may need enhancement in future
- No core file modifications

### Additional Notes
- This task has the most complex logic of Phase 1 tools
- Pre-clustering is a smart optimization for reducing API costs
- Consider documenting the address normalization limitations

---

## SR Engineer Review (SR-Owned)

**REQUIRED: SR Engineer MUST complete this section when reviewing/merging the PR.**

*Review Date: 2025-12-18*

### SR Engineer Metrics

```
| Phase | Turns | Tokens | Time |
|-------|-------|--------|------|
| Planning (Plan) | 1 | ~5K | 3 min |
| PR Review (Batch) | 4 | ~40K | 15 min |
| Feedback/Revisions | 0 | 0 | 0 min |
| **SR Total** | 5 | ~45K | 18 min |
```

Note: This was a batch review of TASK-315, TASK-316, and TASK-317 in a single PR. Metrics are shared across all three tasks (divide by 3 for per-task estimate).

### Review Summary

**Architecture Compliance:** PASS
**Security Review:** PASS
**Test Coverage:** Adequate (16 tests, 80%+ coverage)

**Review Notes:**
- Most complex of the three tools with pre-clustering optimization
- Pre-clustering by address skips LLM for single-address case (cost savings)
- UUID generation via uuid package properly integrated
- Date range calculation handles invalid dates gracefully
- Contact aggregation deduplicates by email/name key
- Summary generation provides human-readable cluster descriptions
- Address normalization is intentionally basic (lowercase, trim) - documented as MVP scope
- Tests verify LLM bypass for single-address optimization
- All acceptance criteria met

### Merge Information

**PR Number:** #161
**Merge Commit:** efabacf
**Merged To:** int/ai-tools
